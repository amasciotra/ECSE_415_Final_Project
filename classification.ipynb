{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification.ipynb\n",
    "Date: November 29th, 2018  \n",
    "Course: ECSE415, McGill University  \n",
    "Authors:  \n",
    "*Shawn Vosburg  \n",
    "Tristan Bouchard  \n",
    "Alex Masciotra  \n",
    "Nayem Alam  \n",
    "Thomas Philippon *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: The classification files folder must be found in the same folder as this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries. Strategy: Find HoG features of each image and build SVM with them.\n",
    "#For second classifier, try Kmeans or Kneighboors\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Declare Constants\n",
    "CLASSIFY_DIM = (128,128)   #Size of the training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presently loading 2284 images from: bicycle\n",
      "Presently loading 1982 images from: motorcycle\n",
      "Presently loading 1751 images from: non-motorized_vehicle\n",
      "Presently loading 6262 images from: pedestrian\n",
      "Presently loading 5120 images from: single_unit_truck\n",
      "Presently loading 9679 images from: work_van\n"
     ]
    }
   ],
   "source": [
    "#Import training images\n",
    "folder = \"./MIO-TCD-Classification/train/\"\n",
    "vehicleDir  = [                                  #Main Directory of Training images\n",
    "#    \"articulated_truck\",        #10346 imgs\n",
    "#    \"background\",               #160000 imgs\n",
    "    \"bicycle\",                  #2284 imgs\n",
    "#    \"bus\",                      #10316 imgs\n",
    "#    \"car\",                      #260518 imgs\n",
    "    \"motorcycle\",               #1982 imgs\n",
    "    \"non-motorized_vehicle\",    #1751 imgs\n",
    "    \"pedestrian\",               #6262 imgs\n",
    "#    \"pickup_truck\",             #50906 imgs\n",
    "    \"single_unit_truck\",        #5120 imgs\n",
    "    \"work_van\"]                 #9679 imgs\n",
    "#Some vehicletypes are commented out as they take too much time to load. After writing code, will remove comment.\n",
    "\n",
    "vehicleTypes = {}                                #This is the main hash that will map the vehicles type to a number. Maps string to index.\n",
    "vehicleImgArr,vehicleLabels = [],[]\n",
    "idx = 0\n",
    "\n",
    "#Build Hash Table\n",
    "for bucket in os.listdir(folder):\n",
    "    vehicleTypes[bucket] = idx\n",
    "    idx +=1\n",
    "\n",
    "#Loop across directory to fetch all images\n",
    "for typeName in vehicleDir:\n",
    "    vehicleTypeDir = folder + typeName+\"/\"\n",
    "    print(\"Presently loading \" + str(len(os.listdir(vehicleTypeDir))) + \" images from: \" + typeName)\n",
    "    \n",
    "    #fetch images\n",
    "    for imgPath in os.listdir(vehicleTypeDir):\n",
    "        img = cv2.imread(vehicleTypeDir+imgPath)\n",
    "        img = cv2.resize(img,CLASSIFY_DIM)       #Resize images so that they are all CLASSIFY_DIM in size\n",
    "        vehicleImgArr.append(img)\n",
    "        vehicleLabels.append(vehicleTypes[typeName])          #Have a seperate array with the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute HOG features of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HoGFromImageArr(imgArr,cs,bs,nb):\n",
    "    \"\"\" This function takes in an image array and HoG param and returns the computed histogram for the image array\n",
    "        imgArr = image array. all images must be same resolution. \n",
    "        cs = cell size in pixel x pixel (height x width)\n",
    "        bc = bin size in cell x cell (height x width)\n",
    "        nb = number of bins\n",
    "\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "    # create HoG Object\n",
    "    # winSize is the size of the image cropped to an multiple of the cell size\n",
    "    hog = cv2.HOGDescriptor(_winSize=(imgArr[0].shape[1] // cs[1] * cs[1],\n",
    "                                      imgArr[0].shape[0] // cs[0] * cs[0]),\n",
    "                            _blockSize=(bs[1] * cs[1],\n",
    "                                        bs[0] * cs[0]),\n",
    "                            _blockStride=(cs[1], cs[0]),\n",
    "                            _cellSize=(cs[1], cs[0]),\n",
    "                            _nbins=nb)\n",
    "    \n",
    "    \n",
    "    n_cells = (imgArr[0].shape[0] // cs[0], imgArr[0].shape[1] // cs[1])\n",
    "    for img in imgArr:\n",
    "        \n",
    "\n",
    "        # Compute HoG features\n",
    "        hog_feats = hog.compute(img)\\\n",
    "                       .reshape(n_cells[1] - bs[1] + 1,\n",
    "                                n_cells[0] - bs[0] + 1,\n",
    "                                bs[0], bs[1], nb) \\\n",
    "                       .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "\n",
    "        # hog_feats now contains the gradient amplitudes for each direction,for each cell of its group for each group.\n",
    "        # Indexing is by rows then columns.\n",
    "\n",
    "        # computation for BlockNorm\n",
    "        gradients = np.full((n_cells[0], n_cells[1], 8), 0, dtype=float)\n",
    "        cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "        #Add each contributions to the histogram.\n",
    "        for off_y in range(bs[0]):\n",
    "            for off_x in range(bs[1]):\n",
    "                gradients[off_y:n_cells[0] - bs[0] + off_y + 1,\n",
    "                          off_x:n_cells[1] - bs[1] + off_x + 1] += \\\n",
    "                    hog_feats[:, :, off_y, off_x, :]\n",
    "                cell_count[off_y:n_cells[0] - bs[0] + off_y + 1,\n",
    "                           off_x:n_cells[1] - bs[1] + off_x + 1] += 1\n",
    "\n",
    "        # Average gradients\n",
    "        gradients /= cell_count\n",
    "        arr = np.append(arr,gradients)\n",
    "    return arr.reshape(len(imgArr),gradients.shape[0],gradients.shape[1],gradients.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-e80d7284ca7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m  \u001b[1;31m# number of orientation bins\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mvehicleHOGArr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHoGFromImageArr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicleImgArr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-5ddcbaac7061>\u001b[0m in \u001b[0;36mHoGFromImageArr\u001b[1;34m(imgArr, cs, bs, nb)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# Average gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mcell_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgArr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5164\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5165\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5166\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Deducing values of required variables. \n",
    "#Since HoG features must be (32,32,8) in size, there must be a 2D-array of 32x32 cells with each containing 8 bins.\n",
    "#Since image is 128x128, each cell's side is 128/32 = 4px in length. (1 cell = 4x4 pixels)\n",
    "#Blocks must cover a 4x4 cell neighborhood (Assume 50% overlap between blocks).\n",
    "#Arbitrarly decide number of bins to be 8. \n",
    "\n",
    "cell_size = (4,4)  # h x w in pixels\n",
    "block_size = (4,4)  # h x w in cells\n",
    "nbins = 8  # number of orientation bins\n",
    "\n",
    "vehicleHOGArr = HoGFromImageArr(vehicleImgArr,cell_size,block_size,nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27078\n"
     ]
    }
   ],
   "source": [
    "print(len(vehicleImgArr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
